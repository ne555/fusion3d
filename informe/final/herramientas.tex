\section{Base de datos}
Uno de los supuestos de este proyecto era contar con un repositorio propio de
mallas tridimensionales.
Para la creación de este repositorio,
se utilizarían los algoritmos de reconstrucción desarrollados en \cite{Pancho},
ubicando al objeto de interés end una base giratoria y realizando capturas
en ángulos espaciados hasta completar una vuelta.
De esta forma, las posiciones de las vistas describirían un círculo centrado en el objeto y
cada captura contendría información de posición ($xyz$) y de textura ($rgb$).
Debido a los tiempos requeridos para calibrar el dispositivo de captura,
este repositorio nunca se materializó,
 por lo que fue necesario buscar otro con características similares.

%\begin{itemize}
%	\item redwood, freibug:
%	rgb y profundidad, pero el movimiento es pequeño y libre
%	(tendría que eliminar intermedios)
%\item middlebury
%	base giratoria, pero sólo RGB
%	(tendría que generar el mapa de profundidad)
%\item stanford
%	base giratoria, nube de puntos, sin textura.
%	Se optó por esta.
%	Se decidió no generar artificialmente los puntos de textura para tener un
%	caso más real.
%\end{itemize}

Se decidió utilizar \emph{The Stanford 3D Scanning Repository}\cite{StanfordScanRep} que brinda
acceso a escaneos tridimensionales y reconstrucciones detalladas para ser
usados en investigación.

Las capturas fueron obtenidas mediante un escáner láser de barrido Cyberware
3030~MS.  Se realizaron escaneos del objeto en diversas posiciones sobre una
base giratoria y luego estas capturas fueron combinadas para producir una única
malla triangular utilizando el método de \emph{zippering} o el de
\emph{volumetric merging}, ambos desarrollados en
Stanford\cite{StanfordScanRep}. \Nota{si no explico esos métodos, volarlos de acá\\}

La base de datos provee un archivo de configuración con las transformaciones de
alineación requeridas por cada captura.
Estas transformaciones fueron obtenidas realizando la registración de cada captura
contra un escaneo cilíndrico del objeto mediante un método semiautomático, donde el usuario
usuario establece una alineación inicial que luego es ajustada mediante un algoritmo
basado en ICP\cite{Turk:1994:ZPM:192161.192241}.

De esta base de datos se utilizaron los modelos
	\texttt{armadillo},
	\texttt{bunny},
	\texttt{dragon},
	\texttt{drill} y
	\texttt{happy},
los cuales presentan distintos niveles de detalles, cantidad de escaneos y niveles de ruido.


\begin{figure}
	\Imagen{example-image-a}
	\caption{\label{fig:stanfod_models}\TODO{Modelos de la base de datos Stanford.}}
\end{figure}


Desgraciadamente, no se cuenta con información de color en estos escaneos.
Se decidió adaptar los algoritmos a esta situación, en lugar de agregar
artificialmente valores de color para los puntos.


\section{Tecnologías}
	%Intro
	A continuación se mencionan las principales herramientas de software
	utilizadas en el desarrollo de programas de reconstrucción tridimensional.

	\subsection{KinectFusion}
	Es el algoritmo desarrollado por Microsoft para lograr reconstrucciones
	tridimensionales utilizando el dispositivo Kinect.

	%kinectfusion_real-time_3d_reconstruction_and_interaction_using_a_moving_depth_camera
	Debido a que uno de sus objetivos era lograr una implementación en tiempo
	real, el algoritmo de registración requiere de poca variación
	de la posición relativa cámara-objeto entre capturas, por lo que no fue utilizado.

	Para realizar la fusión utiliza una variación del método de
	\emph{volumetric merging} sobre GPU.\cite{Izadi:2011:KRR:2047196.2047270}

	%Suposiciones:
	%transforma el sistem en uno lineal, la transformación entre capturas es un incremento pequeño
	%sistema 6x6 (3 translaciones, 3 rotaciones)
	%utiliza todos los puntos porque tiene gpu




	\subsection{Open Source Computer Vision Library (OpenCV)}
	Es una biblioteca de código abierto de visión computacional y aprendizaje
	maquinal.  Cuenta con módulos de procesamiento de imágenes de profundidad y
	registración.

	En un principio se consideró utilizar la información de textura de las
	capturas para poder lograr la registración, pero debido a que la base de
	datos utilizada sólo contenía información geométrica  no se utilizarán las
	funcionalidades de esta biblioteca.

	\subsection{\emph{The Point Cloud Library} (PCL)}
	Es un framework de código abierto multiplataforma para el procesado de
	imágenes 2D/3D y nubes de puntos.
	Provee numerosos algoritmos modernos para reducción de ruido, extracción de
	puntos salientes, cálculo de descriptores, registración, reconstrucción de
	superficies, entre otros.

	La documentación incluye tutoriales para cada módulo de la biblioteca y
	además se cuenta con listas de correos y canales de IRC para brindar
	soporte.

	PCL se encuentra disponible para ser usada en C++.
	Debido al uso intensivo de código templatizado, la compilación del
	código cliente requiere de un tiempo considerable (aproximadamente un minuto).
	Existen proyectos para portarla a Python y Java, pero no se encuentran
	suficientemente avanzados.

	\subsection{CloudCompare, Meshlab}
	Son programas de procesamiento y edición de mallas de puntos 3D.  Presentan
	herramientas de registración semiautomática (a partir de puntos
	seleccionados por el usuario), y cuentan con una implementación del
	algoritmo \emph{Poisson Surface Reconstruction} para reconstrucción de
	superficies.

	Se utilizarán especialmente para visualización y comparación de resultados.

