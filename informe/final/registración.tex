\section{Módulo de registración}
	%¿Qué es la registración?
	%mover al marco teórico
	El módulo de registración se encarga de obtener las transformaciones de rotación y translación
	que lleven cada vista a un sistema global de forma
	que las zonas comunes encajen perfectamente.

	Aunque
	el algoritmo de \emph{Iterative Closest Point} (ICP) se ha convertido en el
	método dominante para realizar la registración de modelos tridimensionales
	utilizando únicamente la información de geometría de los mismos\cite{Rusinkiewicz02real-time3d},
	y a pesar que existe garantía de convergencia del método
	hacia un mínimo local, éste puede no ser el mínimo global buscado.
	Por esta razón,
	es necesario proveer una alineación inicial
	lo suficientemente cercana para obtener una registración correcta\cite{regBesl92}.

	Debido a esto, y considerando que la distancia entre capturas sucesivas es considerable,
	se desarrollaron algoritmos para obtener una alineación inicial
	con cada par de capturas para luego refinar la registración mediante ICP.
	Estos algoritmos constan de los siguientes pasos:
	\begin{enumerate}
		\item Selección de puntos de la entrada.
		\item Cálculo de descriptores y determinación de correspondencias.
		\item Filtrado de correspondencias.
		\item Estimación de la transformación de alineación.
	\end{enumerate}
	Variaciones en la ejecución de estos pasos nos permiten implementar diversos métodos.

	Utilizando la primera captura para definir el sistema de coordenadas
	global, cada nueva vista se alinea con la anterior hasta completar una
	vuelta sobre el objeto, propagando el error de registración.
	Por esta razón, se incorporó un algoritmo de corrección de bucle al proceso de registración
	(figura~\ref{fig:flow_registracion}).

	\begin{figure}
		\Imagen{uml/registration_flow.pdf}
		\caption[Diagrama de flujo de la registración]{\label{fig:flow_registracion}Diagrama de flujo de la registración.}
	\end{figure}

	A continuación se describen dos métodos para calcular la alineación inicial entre un par de capturas.

	\subsection{Alineación mediante \emph{sample consensus}}
		\subsubsection{Selección de keypoints}
			En base a los resultados obtenidos por \cite{ISS},
			se consideró utilizar el algoritmo de detección de keypoints basado en \emph{Intrinsic Shape Signatures} (algoritmo~\ref{alg:iss}),
			el cual se halla implementado en PCL en la clase \texttt{ISSKeypoint3D}, permitiendo
			definir el radio de la vecindad y el nivel de disimilitud de los eigenvalores.

			\begin{algorithm}
				\begin{algorithmic}[1]
					\Function{ISS Keypoints}{nube, $r_1$, $\mbox{umbral}_1$, $\mbox{umbral}_2$, $r_2$}
						\State keypoints $\gets\emptyset$
						\ForAll{$p \in \mbox{nube.puntos}$}
							\State vecinos $\gets$ obtener puntos cercanos(nube, p, $r_1$)
							\State m $\gets$ matriz de covarianza(vecinos)
							\State $\lambda\gets\text{eigenvalores}(m)$
							\If{$\lambda_1/\lambda_2 > \text{umbral}_1$ and $\lambda_2/\lambda_3 > \text{umbral}_2$}
								\State keypoints.insert(p)
							\EndIf
						\EndFor
						\State\Return Non-Max Suppression(keypoints, $r_2$)
					\EndFunction
				\end{algorithmic}
				\caption[Determinación de los keypoints mediante ISS]{\label{alg:iss}Determinación de los keypoints mediante ISS}
			\end{algorithm}

			%ver bien el problema
			Sin embargo, no pudieron encontrarse los parámetros adecuados.
			Al observar las zonas comunes en los casos de estudio
			utilizados como referencia durante el desarrollo,
			eran pocos los keypoints que
			realmente se encontraban lo suficientemente cerca como para generar
			una correspondencia válida (figura~\ref{fig:iss_key}).


			%A partir de acá ref Rusu FPFH
			Por esta razón, se cambió el método de selección de keypoints,
			eligiendo un análisis de persistencia multiescala:
			\begin{enumerate}
				\item Por cada punto de la nube se calcula su descriptor para distintos tamaños de vecindad (escala).
				\item A partir de todos los descriptores en todas las escalas se estima una distribución gaussiana que los aproxime.
				\item Los keypoints quedan definidos como aquellos puntos cuyos descriptores se encuentran alejados de la media\cite{Rusu:2009:FPF:1703435.1703733}.
			\end{enumerate}
			El algoritmo se encuentra implementado en PCL en la clase
			\texttt{Multiscale\-Feature\-Persistence} permitiendo ajustar las
			escalas a utilizar, el umbral para ser considerado saliente y el descriptor a utilizar.
			Debido a que es necesario calcular un descriptor para cada punto, y
			además en diferentes escalas, se eligió utilizar el método
			\emph{Fast Point Feature Histograms} (FPFH) para su construcción,
			el cual es lineal en la cantidad de puntos de la vecindad.
			%Este método calcula un histograma de los ángulos entre las normales del punto y sus vecinos\cite{Rusu:2009:FPF:1703435.1703733}.

			Con este algoritmo, los keypoints se agrupan formando líneas en zonas de cambio brusco de curvatura (figura~\ref{fig:multiscale_key}).


			\begin{figure}
				\centering
				\begin{subfigure}{\linewidth}
					\Imagen{img/iss_happy}
					\caption[Keypoints ISS]{\label{fig:iss_key}Keypoints ISS}
				\end{subfigure}

				\begin{subfigure}{\linewidth}
					\Imagen{img/multiscale_happy}
					\caption[Keypoints FPFH de persistencia multiescala]{\label{fig:multiscale_key}Keypoints FPFH de persistencia multiescala.}
				\end{subfigure}
				\caption[Visualización de los keypoints]{\label{fig:keypoints}Visualización de los keypoints calculados en las vistas
					\texttt{happy\_0} (verde) y \texttt{happy\_24} (rojo).
					A la derecha se seleccionaron aquellos cuyo par
					más cercano se encontraban a menos de 4 veces la resolución
					de la nube.}
			\end{figure}



		\subsubsection{Estimación de la transformación}
			Se utilizó el algoritmo de \emph{sample consensus initial alignment
			(SAC-IA)} para obtener una estimación inicial de la transformación de alineación.
			Este algoritmo consiste en:
			\begin{enumerate}
				\item Seleccionar al azar \emph{m} puntos de la nube A.
				\item Por cada punto, buscar aquellos con descriptores similares en B y seleccionar uno al azar.
				\item Calcular la transformación definida por estos puntos y sus correspondencias.
					Es decir, calcular la transformación que minimice
					\[ \sum |b_j - T(a_j)| \]
					para los puntos muestreados.
				\item Calcular una medida del error de transformación.
					Es decir, calcular el error
					\[ \sum |b_j - T(a_j)| \]
					para todos los puntos de la nube.
				\item Repetir varias veces y devolver aquella transformación que produzca el menor error.\cite{Rusu:2009:FPF:1703435.1703733}
			\end{enumerate}

		\subsubsection{Búsqueda de parámetros}
			%Para determinar los valores idóneos de los parámetros del algoritmo
			Para ajustar los valores de los parámetros del algoritmo
			se eligieron dos modelos de la base de datos Stanford\cite{StanfordScanRep}
			Seleccionando pares de capturas de cada modelo, se estableció un conjunto de parámetros que alinee apropiadamente a todos los pares,
			buscando, además, independencia respecto a las características geométricas del modelo.

			Los modelos escogidos fueron \texttt{happy stand} y \texttt{bunny} debido a las diferencias geométricas que presentan:
			\begin{itemize}
				\item Las capturas de \texttt{happy stand} se realizaron a intervalos de ángulos equiespaciados (cercanos a $24^{\circ}$) y
					presentan zonas suaves en la base, vientre y espalda.
				\item Los ángulos entre las capturas de \texttt{bunny} son más variados y espaciados, yendo desde $35^{\circ}$ hasta $90^{\circ}$,
				y se observa una superficie más irregular por todo el cuerpo (figura~\ref{fig:stanford_models}).
				%FIXME: aclaración de ángulo de 90
				% o ignorar el de 90 (ver cuánto era) 35-55: se ignoran alineaciones 3-4, 4-5
				% sí, ignorar, ver ángulos, y decir que se descartó captura 4
				% se descarta en la búsqueda de parámetros, pero se realiza la prueba
				%FIXME: figura bunny solo (o de sus capturas)
			\end{itemize}

			Primero se trabajó sobre el modelo \texttt{happy stand}.
			Se observó que una selección de keypoints demasiado agresiva no permitía la convergencia del algoritmo de SAC-IA,
			mientras que una selección demasiado permisiva elevaba el costo computacional de forma excesiva.
			Finalmente, utilizando escalas diádicas y estableciendo un umbral de un desvío y medio
			se obtuvieron buenos resultados en la mayoría de las capturas (figura~\ref{fig:dif_rot_happy_sac}).

			Sin embargo, fue imposible hallar los parámetros adecuados para el modelo \texttt{bunny}.
			Exceptuando las alineaciones entre las capturas \{315, 000\} y \{000, 045\},
			el algoritmo de registración establecía correspondencias completamente erróneas (figura~\ref{fig:align_sac}).
			Por esta razón, no se continuó con el desarrollo de este algoritmo.

			%FIXME: nunca se definió ground truth
			\begin{figure}
				\input{graph/dif_rot_happy_sac.tex}
				\caption[Diferencias en la rotación estimada para el objeto \texttt{happy stand} (SAC-IA)]
				{\label{fig:dif_rot_happy_sac}Diferencias absolutas entre la rotación estimada y el \emph{ground truth} para el objeto \texttt{happy stand}
				utilizando el algoritmo de sample consensus.}
			\end{figure}

			\begin{figure}
				\Imagen{img/bun_sac_270_315}
				\caption[Fallo en el algoritmo de \emph{sample consensus}]{\label{fig:align_sac}Ejemplo de fallo del algoritmo de \emph{sample consensus} producto de malas correspondencias
				(par de capturas \{270, 315\} del modelo \texttt{bunny})}
			\end{figure}


	%El que tengo ahora
	\subsection{Alineación mediante búsqueda de clúster}
		En este método alternativo de alineación no se seleccionan keypoints,
		sino que se realiza un submuestreo uniforme de los puntos de la nube
		para reducir el costo computacional.
		Además del descriptor, en cada punto se estableció un marco de referencia
		que permite estimar una transformación de alineación
		considerando solamente los dos puntos que conforman una correspondencia\cite{ISS}.
		Entonces, se procede a un proceso de votación para determinar la alineación final.

		Para determinar el marco de referencia se utiliza la matriz de covarianza de la vecindad del punto:
		\begin{itemize}
			\item Se computan los eigenvalores ${\lambda_1, \lambda_2, \lambda_3}$ en orden decreciente y sus eigenvectores correspondientes
				$e^{1}, e^{2}, e^{3}$.
			\item Debido a que $e^{3}$ representa la normal del punto, se ajusta su sentido para que coincida con el del eje $z$.
			\item Los otros ejes se definen mediante $e^{1}$ y $e^{1} \times e^{3}$.
		\end{itemize}
		Se presenta una ambigüedad en el marco de referencia según el sentido que se le asigne a $e^{1}$ (figura~\ref{fig:marco_referencia_iss}),
		la cual se resuelve definiendo un eje de giro para la alineación.

		\begin{figure}
			\Imagen{diagram/marco_referencia_iss}
			\caption[Marcos de referencia]{\label{fig:marco_referencia_iss}Marcos de referencia. Se observa una ambigüedad equivalente a un giro de $180^{\circ}$ sobre el eje $e^{3}$ \RefImagen{ISS}.}
		\end{figure}

		Para establecer las correspondencias se eligió nuevamente el descriptor FPFH,
		comparando los histogramas entre cada par de puntos mediante la distancia $\chi^2$:
		\[ \chi^2 = \sum_{j=1}^{N} \frac{\left(a_j - b_j\right)^2}{a_j + b_j} \]
		Para identificar y eliminar las correspondencias erróneas se utilizan
		los marcos de referencia y las suposiciones de ubicación de la cámara
		en la obtención de las capturas.  Es decir, se descartan aquellas correspondencias que
		requieren un movimiento en $y$ excesivo o una rotación sobre un eje no vertical (figura~\ref{fig:bun_corr}).

		\begin{figure}
			\centering
			\Imagen{img/bun_corr_clust_edit}
			\caption{\label{fig:bun_corr}Correspondencias supervivientes luego de realizar el descarte según la transformación estimada por cada marco de referencia.}
		\end{figure}

		Cada correspondencia define un ángulo de giro $\theta$ sobre
		el eje $y$ y una translación en el plano $xz$, observándose una agrupación
		de los parámetros de estas transformaciones (figura~\ref{fig:cluster}).
		Mediante el algoritmo de k-means, se busca el centroide del clúster más grande
		para estimar la transformación final.

		\begin{figure}
			\centering
			\begin{subfigure}{\linewidth}
				\centering
				\input{graph/bun_angles.tex}
				%\caption{Ángulos sobre el eje $y$.}
			\end{subfigure}
			\begin{subfigure}{\linewidth}
				\input{graph/bun_translation.tex}
				%\caption{Translaciones en $x$ y $z$.}
			\end{subfigure}
				\caption[Estimación de la transformación de alineación mediante los marcos de referencia]{\label{fig:cluster}Estimación de la transformación de alineación
				mediante los marcos de referencia de los puntos de cada correspondencia
				entre las capturas \texttt{bun000} y \texttt{bun045}. Los desplazamientos se encuentran medidos en unidades de resolución.}
		\end{figure}

		\subsubsection{Búsqueda de parámetros}
			Para establecer los valores de los parámetros se procedió de la
			misma manera que en el caso del algoritmo de SAC-IA.
			Se definieron umbrales permisivos para el desplazamiento y el ángulo de giro
			($8$ veces la resolución de la nube y $10^\circ$ respecto a la vertical, respectivamente)
			y se realizaron incrementos discretos del tamaño de la vecindad para el cálculo de los marcos de referencia y los descriptores,
			obteniéndose los mejores resultados para una vecindad de $8$ veces la resolución de la nube.

			Para el modelo \texttt{happy}, las diferencias respecto al \emph{ground truth}
			no superaron los $5^{\circ}$, teniendo un error promedio de $2^{\circ}$ (figura~\ref{fig:dif_rot_happy}).
			Tampoco se tuvieron problemas con el modelo \texttt{bunny},
			a pesar de presentar saltos cercanos a $90^{\circ}$ en las alineaciones
			contra la captura \texttt{bun180}. Si bien este salto supera las restricciones impuestas,
			en ningún caso se produjo una diferencia mayor a $5^{\circ}$ respecto al \emph{ground truth} (figura~\ref{fig:clust_bunny}).


			\begin{figure}
				\input{graph/dif_rot_happy.tex}
				\caption[Diferencias en la rotación estimada para el objeto \texttt{happy}]
				{\label{fig:dif_rot_happy}Diferencias absolutas entre la rotación estimada y el \emph{ground truth} para el objeto \texttt{happy},
				para los algoritmos de sample consensus (claro) y búsqueda de clúster (oscuro).}
			\end{figure}

			\begin{figure}
				\input{graph/dif_rot_bun.tex}
				\caption[Diferencias en la rotación estimada para el objeto \texttt{bunny}]
				{\label{fig:clust_bunny}Diferencias absolutas entre la rotación estimada y el \emph{ground truth} para el objeto \texttt{bunny} utilizando el algoritmo de búsqueda de clúster.}
			\end{figure}

			De esta manera, se logró acercar las capturas lo suficiente como
			para intentar alinearlas por ICP.

			%\begin{figure}
			%	\Imagen{img/bun_clust_270_315}
			%	\caption[Registración exitosa mediante el uso de búsqueda de clúster]
			%	{\label{fig:clust_bun_good}Registración exitosa mediante el uso de búsqueda de clúster (par de capturas \{270, 315\} del modelo \texttt{bunny}).}
			%\end{figure}


			%parámetros
	    % sample_ratio_(0.25),
	    %  feature_radius_(8),
	    %  resolution_(0),
	    %  y_threshold_(8),
	    %  max_iterations_(3),
	    %  n_clusters_(3) {
		%	this->set_axis_threshold_(10*M_PI/180);


	\subsection{Refinamiento}
	Para ajustar las alineaciones iniciales se realiza una segunda alineación utilizando
	el algoritmo de ICP provisto por la biblioteca PCL.
	Se consideran únicamente las áreas solapadas, restringiendo el espacio de
	búsqueda de las correspondencias, y se minimiza la distancia entre los puntos
	de la nube a transformar hacia los planos definidos por las normales en la nube objetivo.

	%@@@
	%\clearpage
	Luego, para reducir el error propagado por cada alineación, se realiza una
	corrección de bucle ajustando la última captura para que correspondiese con la primera,
	y agregando esta transformación a las otras alineaciones ponderándola de forma
	proporcional a su posición en el bucle (algoritmo~\ref{alg:correccion_bucle}).

	\begin{algorithm}
		\begin{algorithmic}[1]
			\Function{Corrección de bucle}{nubes, N}
				\State peso $\gets \frac{1}{N-1}$
				\State error $\gets$ Alineación(desde=nubes[1], hacia=nubes[N])
				\State $[q|t]$ $\gets$ inversa(error)
				\ForAll{$K \in 1:N$}
					\State rotación $\gets$ slerp(K * peso, $q$, Identidad)
					\State translación $\gets$ K * peso * $t$
					\State nubes[K] $\gets$ transformar([rotación|translación], nubes[K])
				\EndFor
			\EndFunction
		\end{algorithmic}
		\caption[Corrección de la propagación del error de alineación]{\label{alg:correccion_bucle}Corrección de la propagación del error de alineación.}
	\end{algorithm}
